<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>文字转语音TTS</title>
  <meta name="description"
    content="概述">

  <link rel="shortcut icon" href="/img/favicon.ico">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://huailiang.github.io/blog/2019/tts/">

</head>

<body>
  <main>
    <header class="site-header">
  <div class="container">
    <h1><a href="/">Hom<span>e</span></a></h1>

    <button type="button" class="sliding-panel-button">
      <span></span>
      <span></span>
      <span></span>
    </button>

    <nav class="navbar sliding-panel-content">
      <ul>
        
        <li><a href="/about" title="About">About</a>
        </li>
        
        <li><a href="/blog" title="Blog">Blog</a>
        </li>
        
       <li><a href="/category/" target="_blank"><i class="icon icon-feed"></i></a></li>
      </ul>
    </nav>
  </div>
</header>

<div class="sliding-panel-fade-screen"></div>
    <script type="text/javascript" src="/js/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
  });

</script>
    <div class="container">
      <article role="article" class="post">

  <div class="card">
    <header class="post-header">
      <h1 class="post-title">文字转语音TTS</h1>
      <p class="post-meta">Dec 13, 2019 •
        Huailiang</p>
    </header>

    <div class="post-content">
      <h2 id="概述">概述</h2>

<p>Tacotron2是由Google Brain 2017年提出来的一个语音合成框架<a href="https://arxiv.org/abs/1712.05884">Tacotron2</a>:一个完整神经网络语音合成方法。模型主要由三部分组成：<br />
• 声谱预测网络：一个引入注意力机制（attention）的基于循环的Seq2seq的特征预测网络，用于从输入的字符序列预测梅尔频谱的帧序列。<br />
• 声码器（vocoder）：一个WaveNet的修订版，用预测的梅尔频谱帧序列来生成时域波形样本。<br />
• 中间连接层：使用低层次的声学表征-梅尔频率声谱图来衔接系统的两个部分。</p>

<p><img src="/img/post-ml/tts2.jpg" alt="" /></p>

<h2 id="预处理">预处理</h2>

<h3 id="文字处理">文字处理</h3>

<p>一般传给模型的编码好的词向量，而不是原始的文字， 因此我们需要对文字进行编码,压缩到一个固定长度的向量。文字主要由字幕和标点、空格等组成， 这里先将文字转换成对应的向量， 如果是汉字的话， 可以先转成拼音。 步骤如下：</p>

<ol>
  <li>
    <p>先清除文字里陌生字符， 可以使用正则表达式匹配</p>

    <div class="language-py highlighter-rouge"><pre class="highlight"><code><span class="n">_curly_re</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="s">r'(.*?)</span><span class="err">\</span><span class="s">{(.+?)</span><span class="err">\</span><span class="s">}(.*)'</span><span class="p">)</span>
</code></pre>
    </div>
  </li>
  <li>
    <p>对每个字母进行编码, 得到一个词向量， 然后传给模型</p>
    <div class="language-py highlighter-rouge"><pre class="highlight"><code> <span class="n">_pad</span> <span class="o">=</span> <span class="s">'_'</span>
 <span class="n">_punctuation</span> <span class="o">=</span> <span class="s">'!</span><span class="se">\'</span><span class="s">(),.:;? '</span>
 <span class="n">_special</span> <span class="o">=</span> <span class="s">'-'</span>
 <span class="n">_letters</span> <span class="o">=</span> <span class="s">'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'</span>

 <span class="c"># Prepend "@" to ARPAbet symbols to ensure uniqueness:</span>
 <span class="n">_arpabet</span> <span class="o">=</span> <span class="p">[</span><span class="s">'@'</span> <span class="o">+</span> <span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">cmudict</span><span class="o">.</span><span class="n">valid_symbols</span><span class="p">]</span>

 <span class="c"># Export all symbols:</span>
 <span class="n">symbols</span> <span class="o">=</span> <span class="p">[</span><span class="n">_pad</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">_special</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">_punctuation</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">_letters</span><span class="p">)</span> <span class="o">+</span> <span class="n">_arpabet</span>

 <span class="k">def</span> <span class="nf">sequence_to_text</span><span class="p">(</span><span class="n">sequence</span><span class="p">):</span>
     <span class="n">result</span> <span class="o">=</span> <span class="s">''</span>
     <span class="k">for</span> <span class="n">symbol_id</span> <span class="ow">in</span> <span class="n">sequence</span><span class="p">:</span>
         <span class="k">if</span> <span class="n">symbol_id</span> <span class="ow">in</span> <span class="n">_id_to_symbol</span><span class="p">:</span>
             <span class="n">s</span> <span class="o">=</span> <span class="n">_id_to_symbol</span><span class="p">[</span><span class="n">symbol_id</span><span class="p">]</span>
             <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s">'@'</span><span class="p">:</span>
                 <span class="n">s</span> <span class="o">=</span>  <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
             <span class="n">result</span> <span class="o">+=</span> <span class="n">s</span>
     <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'}{'</span><span class="p">,</span> <span class="s">' '</span><span class="p">)</span>
</code></pre>
    </div>
  </li>
</ol>

<h3 id="声音处理">声音处理</h3>

<p>一般很难直接能从声音的波形图里，提取出声音的特征，需要先进行转换。 一般的话，都是转换为梅尔图谱或者梅尔频率倒谱系数 MFCC， 在<a href="https://arxiv.org/abs/1712.05884">谷歌的论文</a>里转换成了梅尔图谱。</p>

<p>使用librosa或者scipy.io.wavfile 加载到内存， 得到numpy array</p>

<div class="language-py highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.io.wavfile</span> <span class="kn">import</span> <span class="n">read</span>
<span class="n">sampling_rate</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">read</span><span class="p">(</span><span class="n">full_path</span><span class="p">)</span>
</code></pre>
</div>

<p>进行加窗、短时傅里叶变换进入复数域</p>

<div class="language-py highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.signal</span> <span class="kn">import</span> <span class="n">get_window</span>

<span class="c"># get window and zero center pad it to filter_length</span>
<span class="n">fft_window</span> <span class="o">=</span> <span class="n">get_window</span><span class="p">(</span><span class="n">window</span><span class="p">,</span> <span class="n">win_length</span><span class="p">,</span> <span class="n">fftbins</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">fft_window</span> <span class="o">=</span> <span class="n">pad_center</span><span class="p">(</span><span class="n">fft_window</span><span class="p">,</span> <span class="n">filter_length</span><span class="p">)</span>
<span class="n">fft_window</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">fft_window</span><span class="p">)</span><span class="o">.</span><span class="nb">float</span><span class="p">()</span>
<span class="n">forward_basis</span> <span class="o">*=</span> <span class="n">fft_window</span>
<span class="n">inverse_basis</span> <span class="o">*=</span> <span class="n">fft_window</span>
<span class="c"># 加窗</span>
<span class="n">forward_transform</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv1d</span><span class="p">(</span>
        <span class="n">input_data</span><span class="p">,</span>
        <span class="n">Variable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">forward_basis</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
        <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c"># 短时傅里叶变换       </span>
<span class="n">cutoff</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">filter_length</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">real_part</span> <span class="o">=</span> <span class="n">forward_transform</span><span class="p">[:,</span> <span class="p">:</span><span class="n">cutoff</span><span class="p">,</span> <span class="p">:]</span>  <span class="c"># 实部</span>
<span class="n">imag_part</span> <span class="o">=</span> <span class="n">forward_transform</span><span class="p">[:,</span> <span class="n">cutoff</span><span class="p">:,</span> <span class="p">:]</span>  <span class="c"># 虚部</span>
<span class="n">magnitude</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">real_part</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">imag_part</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">mel_output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mel_basis</span><span class="p">,</span> <span class="n">magnitudes</span><span class="p">)</span>
</code></pre>
</div>

<h2 id="傅里叶变换">傅里叶变换</h2>

<p>上述处理声音用到短时傅里叶变换，如果已经对傅里叶变换了解可以跳过此小节。</p>

<p>傅立叶变换，表示能将满足一定条件的某个函数表示成三角函数（正弦和/或余弦函数）或者它们的积分的线性组合。在不同的研究领域，傅立叶变换具有多种不同的变体形式，如连续傅立叶变换和离散傅立叶变换。</p>

<p>傅里叶变换把时域信号变为频域信号。在离散傅里叶变换中，频域信号由一系列不同频率的谐波（频率成倍数）组成。scipy.fftpack.fft返回值是一个复数数组，每个复数表示一个正弦波。通常一个波形由振幅，相位，频率三个变量确定，可以从fft的返回值里，获取这些信息。</p>

<p>假设a是时域中的周期信号，采样频率为Fs，采样点数为N。如果A[N] = fft(a[N])，返回值A[N]是一个复数数组，其中：</p>

<p>• A[0]表示频率为0hz的信号，即直流分量</p>

<p>• A[1:N/2]包含正频率项，A[N/2:]包含负频率项。正频率项就是转化后的频域信号，通常我们只需要正频率项，即前面的n/2项，负频率项是计算的中间结果（正频率项的镜像值）</p>

<p>• A[i] = real + j * imag，是一个复数，相位就是复数的辐角，相位 = arg(real/imag)</p>

<p>• 振幅就是复数的模，振幅 = $\sqrt{real^2+imag^2}$。但是fft的返回值的模是放大值，直流分量的振幅放大了N倍，弦波分量的振幅放大了N/2倍</p>

<div class="language-py highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.fftpack</span> <span class="kn">import</span> <span class="n">fft</span><span class="p">,</span> <span class="n">ifft</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">800</span><span class="p">)</span>

<span class="c"># 设置需要采样的信号，频率分量有80，190和300</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">7</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="mi">80</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> \
    <span class="mf">2.8</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="mi">190</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> \
    <span class="mf">5.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="mi">300</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>

<span class="n">yy</span> <span class="o">=</span> <span class="n">fft</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c"># 快速傅里叶变换</span>
<span class="n">y_real</span> <span class="o">=</span> <span class="n">yy</span><span class="o">.</span><span class="n">real</span>  <span class="c"># 获取实数部分</span>
<span class="n">y_imag</span> <span class="o">=</span> <span class="n">yy</span><span class="o">.</span><span class="n">imag</span>  <span class="c"># 获取虚数部分</span>

<span class="n">yf</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">fft</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>  <span class="c"># 取绝对值</span>
<span class="n">yf1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="nb">abs</span><span class="p">(</span><span class="n">fft</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c"># 归一化处理</span>
<span class="n">yf2</span> <span class="o">=</span> <span class="n">yf1</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">))]</span>  <span class="c"># 由于对称性，只取一半区间</span>

<span class="n">xf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>  <span class="c"># 频率</span>
<span class="n">xf1</span> <span class="o">=</span> <span class="n">xf</span>
<span class="n">xf2</span> <span class="o">=</span> <span class="n">xf</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">))]</span>  <span class="c"># 取一半区间</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">231</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">50</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">50</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">232</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xf</span><span class="p">,</span> <span class="n">y_real</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">233</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xf</span><span class="p">,</span> <span class="n">y_imag</span><span class="p">,</span> <span class="s">'g'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">234</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xf1</span><span class="p">,</span> <span class="n">yf</span><span class="p">,</span> <span class="s">'g'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">235</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xf1</span><span class="p">,</span> <span class="n">yf1</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">236</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xf2</span><span class="p">,</span> <span class="n">yf2</span><span class="p">,</span> <span class="s">'b'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

<p>代码来源<a href="https://gist.github.com/huailiang/45ccce613e77ce860d4e161ee1ca90fe">gist</a>, 运行效果如下：</p>

<p><img src="/img/post-ml/tts5.jpg" alt="" /></p>

<p>(Fig1原始波形，Fig2实数部分, Fig3虚数部分，Fig4绝对值, Fig5归一化，Fig6对称取半)</p>

<p>从上图可以清晰看到傅里叶变换之后， 频域对称性分布(傅立叶变换的共轭对称性)， 归一化之后得到每一个频率的振幅。</p>

<h4 id="stft">STFT</h4>
<p>短时傅里叶变换（STFT，short-time Fourier transform，或 short-term Fourier transform)）是和傅里叶变换相关的一种数学变换，用以确定时变信号其局部区域正弦波的频率与相位。</p>

<p>选择一个时频局部化的窗函数，假定分析窗函数g(t)在一个短时间间隔内是平稳（伪平稳）的，移动窗函数，使f(t)g(t)在不同的有限时间宽度内是平稳信号，从而计算出各个不同时刻的功率谱。短时傅里叶变换使用一个固定的窗函数，窗函数一旦确定了以后，其形状就不再发生改变，短时傅里叶变换的分辨率也就确定了。如果要改变分辨率，则需要重新选择窗函数。短时傅里叶变换用来分析分段平稳信号或者近似平稳信号犹可，但是对于非平稳信号，当信号变化剧烈时，要求窗函数有较高的时间分辨率；而波形变化比较平缓的时刻，主要是低频 信号，则要求窗函数有较高的频率分辨率。</p>

<h4 id="dct">DCT</h4>

<p>由于许多要处理的信号都是实信号，在使用FFT时，对于实信号，傅立叶变换的共轭对称性导致在频域中有一半的数据冗余。</p>

<p>离散余弦变换（DCT）是对实信号定义的一种变换，变换后在频域中得到的也是一个实信号，相比离散傅里叶变换DFT而言, DCT可以减少一半以上的计算。DCT还有一个很重要的性质（能量集中特性）：大多书自然信号（声音、图像）的能量都集中在离散余弦变换后的低频部分，因而DCT在（声音、图像）数据压缩中得到了广泛的使用。由于DCT是从DFT推导出来的另一种变换，因此许多DFT的属性在DCT中仍然是保留下来的。</p>

<p>SciPy.fftpack中，提供了离散余弦变换(DCT)与离散余弦逆变换(IDCT)的实现。我们将上面fft运算改成dct运算， <br />
修改后的<a href="https://gist.github.com/huailiang/343da329a0f1d44b82bc1e8d2c0a08ef">代码</a>运行效果如下:</p>

<p><img src="/img/post-ml/tts6.jpg" alt="" /></p>

<h2 id="编码器-解码器encoder-decoder结构">编码器-解码器(Encoder-Decoder)结构</h2>

<p>在原始的编码器-解码器结构中，编码器(encoder)输入一个序列或句子，然后将其压缩到一个固定长度的向量(向量也可以理解为一种形式的序列)中；解码器(decoder)使用固定长度的向量，将其解压成一个序列。</p>

<p><img src="/img/post-ml/tts1.jpg" alt="" /></p>

<p>最普遍的方式是使用RNN实现编码器和解码器。</p>

<p>编码器将输入序列映射成固定长度的向量，解码器在生成输出序列阶段，利用注意力机制“关注”向量的不同部分。</p>

<h2 id="编码器">编码器</h2>

<p>前置知识</p>

<h3 id="双向rnn">双向RNN</h3>

<p>双向RNN确保模型能够同时感知前向和后向的信息。双向RNN包含两个独立的RNN，一个前向RNN从前向后读入序列(从$f_1$到$f_{Tx}$)，另一个后向RNN从后向前读入序列(从$f_{Tx}$到$f_1$)，最终的输出为两者的拼接。</p>

<p>在Tacotron2中，编码器将输入序列$X=[x_1,x_2,…,x_{T_x}]$映射成序列$H=[h_1,h_2,…,h_{T_x}]$,其中序列H被称作“编码器隐状态”(encoder hidden states)。注意：编码器的输入输出序列都拥有相同的长度，$h_i$之于相邻分量$h_j$拥有的信息等价于$x_i$之于$x_j$所拥有的信息。</p>

<p>在Tacotron2中，每一个输入分量$x_i$就是一个字符。Tacotron2的编码器是一个3层卷积层后跟一个双向LSTM层形成的模块，在Tacotron2中卷积层给予了神经网络类似于N−gram感知上下文的能力。这里使用卷积层获取上下文主要是由于实践中RNN很难捕获长时依赖，并且卷积层的使用使得模型对不发音字符更为鲁棒(如’know’中的’k’)。</p>

<p>经词嵌入(word embedding)的字符序列先送入三层卷积层以提取上下文信息，然后送入一个双向的LSTM中生成编码器隐状态，即：</p>

<script type="math/tex; mode=display">f_{e}=ReLU(F_3*ReLU(F_2*ReLU(F_1*\overline{E}(X))))\\
H=EncoderRecurrency(f_{e})</script>

<p>其中，F1、F2、F3为3个卷积核，ReLU为每一个卷积层上的非线性激活，$\overline{E}$表示对字符序列X做embedding，EncoderRecurrency表示双向LSTM。</p>

<p>编码器隐状态生成后，就会将其送入注意力网络(attention network)中生成上下文向量(context vector)。</p>

<h3 id="注意力机制">注意力机制</h3>

<p>注意力(attention)用作编码器和解码器的桥接，本质是一个上下文权重向量组成的矩阵。</p>

<p><img src="/img/post-ml/tts7.jpg" alt="" /></p>

<script type="math/tex; mode=display">Attention(Query,Source)=\sum_{i=1}^{L_x}similarity(Query,Key_i)*Value</script>

<p>如果在机器翻译(NMT)中，Souce中的Key和Value合二为一，指的是同一个东西，即输入句子中每个单词对应的语义编码。</p>

<h5 id="一般的计算步骤">一般的计算步骤：</h5>

<p>步骤一：Key和Value相似度度量：</p>

<p>• 点积 $Similarity(Query,Key)=Query·Key$ <br />
• cos相似性 $Similarity(Query,Key)=\frac{Query·Key_i}{||Query||*||Key_i||}$<br />
• MLP网络 $Similarity(Query,Key_i)=MLP(Query,Key_i)$<br />
• Key和Value还可以拼接后再内积一个参数向量，甚至权重都不一定要归一化</p>

<p>步骤二：softmax归一化(alignments/attention weights):</p>

<script type="math/tex; mode=display">a_i=softmax(sim_i)=\frac{e^{sim_i}}{\sum_{j=1}^{L_x}e^{sim_j}}</script>

<p>步骤三：Attention数值(context vector)：</p>

<script type="math/tex; mode=display">Attention(Query,Key)=\sum^{L_x}_{i=1}a_i·Value_i</script>

<p>在Tacotron中，注意力计算(attention computation)发生在每一个解码器时间步上，其包含以下阶段：</p>

<p>目标隐状态(上图绿框所示)与每一个源状态(上图蓝框所示)“相比”，以生成注意力权重(attention weights)或称对齐(alignments)：</p>

<p>其中，$h_t$为目标隐状态，$\overline{h_s}$为源状态，score函数常被称作“能量”(energy)，因此可以表示为e。不同的score函数决定了不同类型的注意力机制。</p>

<p>基于注意力权重，计算上下文向量(context vector)作为源状态的加权平均：</p>

<script type="math/tex; mode=display">c_t=\sum_s\alpha_{ts}\overline{h_s}</script>

<p>注意力向量作为下一个时间步的输入</p>

<p>以下是不同的score函数：</p>

<h4 id="基于内容的注意力机制content-based-attention">基于内容的注意力机制(content-based attention)：</h4>

<script type="math/tex; mode=display">e_{ij}=score(s_{i-1},h_j)=v_a^Ttanh(W_as_{i-1}+U_ah_j)</script>

<p>其中，$s_{i−1}$为上一个时间步中解码器的输出(解码器隐状态，decoder hidden states)，$h_j$是编码器此刻输入(编码器隐状态，encoder hidden state j)，$v_a$、$W_a$和$U_a$是待训练参数张量。由于$U_ah_j$是独立于解码步i的，因此可以独立提前计算。基于内容的注意力机制能够将不同的输出与相应的输入元素连接，而与其位置无关。在Tacotron2中使用基于内容的注意力机制时，当输出对应于’s’的Mel频谱帧，模型会寻找所有所有对应于’s’的输入。</p>

<h4 id="基于位置的注意力机制location-based-attention">基于位置的注意力机制(location-based attention)：</h4>

<script type="math/tex; mode=display">e_{ij}=score(\alpha_{i-1},h_j)=v_a^Ttanh(Wh_j+Uf_{i,j})</script>

<p>其中，$f_{i,j}$是之前的注意力权重αi−1经卷积而得的位置特征，$f_i=F∗\alpha_{i−1}$，$v_a$、$W_a$、$U_a$和F是待训练参数。</p>

<p>基于位置的注意力机制仅关心序列元素的位置和它们之间的距离。基于位置的注意力机制会忽略静音或减少它们，因为该注意力机制没有发现输入的内容。</p>

<h4 id="混合注意力机制hybrid-attention">混合注意力机制(hybrid attention)：</h4>

<p>顾名思义，混合注意力机制是上述两者注意力机制的结合：</p>

<script type="math/tex; mode=display">e_{ij}=score(s_{i-1},\alpha_{i-1},h_j)=v_a^T\mathop{tanh}(Ws_{i-1}+Vh_j+Uf_{i,j})</script>

<p>其中，$s_{i−1}$为之前的解码器隐状态，$\alpha_{i−1}$是之前的注意力权重，$h_j$是第j个编码器隐状态。为其添加偏置值b，最终的score函数计算如下：</p>

<p>其中，$v_a$、W、V、U和b为待训练参数，$s_{i−1}$为上一个时间步中解码器隐状态，$h_j$是当前编码器隐状态，$f_{i,j}$是之前的注意力权重$α_{i−1}$经卷积而得的位置特征(location feature)， $f_i=F∗\alpha_{i−1}$。混合注意力机制能够同时考虑内容和输入元素的位置。</p>

<h4 id="tacotron2注意力机制location-sensitive-attention">Tacotron2注意力机制，Location Sensitive Attention</h4>

<script type="math/tex; mode=display">e_{i,j}=score(s_i,c\alpha_{i-1},h_j)=v_a^T\mathop{tanh}(Ws_i+Vh_j+Uf_{i,j}+b)</script>

<p>其中，$s_i$为当前解码器隐状态而非上一步解码器隐状态，偏置值b被初始化为0。位置特征$f_i$使用累加注意力权重$c\alpha_i$卷积而来：</p>

<script type="math/tex; mode=display">f_i=F*c\alpha_{i-1}\\
c\alpha_i=\sum_{j=1}^{i-1}\alpha_j</script>

<p>之所以使用加法累加而非乘法累积，原因如图：</p>

<p><img src="/img/post-ml/tts8.jpg" alt="" /></p>

<p>累加注意力权重，可以使得注意力权重网络了解它已经学习到的注意力信息，使得模型能在序列中持续进行并且避免重复未预料的语音。</p>

<p>整个注意力机制如图：</p>

<p><img src="/img/post-ml/tts10.jpg" alt="" /></p>

<h2 id="解码器">解码器</h2>

<p>解码过程从输入上一步的输出声谱或上一步的真实声谱到PreNet开始，解码过程如图：</p>

<p><img src="/img/post-ml/tts9.jpg" alt="" /></p>

<p>PreNet的输出与使用上一个解码步输出计算而得的上下文向量做拼接，然后整个送入RNN解码器中，RNN解码器的输出用来计算新的上下文向量，最后新计算出来的上下文向量与解码器输出做拼接，送入投影层(projection layer)以预测输出。输出有两种形式，一种是声谱帧，一种是<stop token="">的概率，后者是一个简单二分类问题，决定解码过程是否结束。使用缩减因子(reduction factor)即每一个解码步仅允许预测r(缩减因子)Mel谱帧，能够有效加速计算，减小内存占用。</stop></p>

<h2 id="后处理网络">后处理网络</h2>

<p>一旦解码器完成解码，预测得到的Mel谱被送入一系列的卷积层中以提高生成质量。</p>

<p>后处理网络使用残差(residual)计算：</p>

<script type="math/tex; mode=display">y_{final}=y+y_r</script>

<p>其中，y为原始输入</p>

<p>上式中，</p>

<script type="math/tex; mode=display">y_r=PostNet(y)=W_{ps}f_{ps}+b_{ps}</script>

<p>其中，$f_{ps}=F_{ps,i}*x$，x为上一个卷积层的输出或解码器输出，F为卷积</p>

<h3 id="训练">训练</h3>

<script type="math/tex; mode=display">loss=\frac{1}{n}\sum_{i=1}^{n}(y_{real,i}-y_i)^2+\frac{1}{n}\sum_{i=1}^n(y_{real,i}-y_{final,i})^2+\lambda\sum_{j=1}^p w_j^2</script>

<p>其中，$y_{real}$,i为真实声谱，$y_i$、$y_{final}$,i分别为进入后处理网络前、后的声谱，n为batch中的样本数，λ为正则化参数，p为参数总数，w​为神经网络中的参数。注意，不需要正则化偏置值。</p>


    </div>
  </div>

  <style>
  .post-nav {
    overflow: hidden;
    /* margin-top: 60px; */
    padding: 12px;
    white-space: nowrap;
    /* border-top: 1px solid #eee; */
  }

  .post-nav-item {
    display: inline-block;
    width: 50%;
    white-space: normal;
  }

  .post-nav-item a {
    position: relative;
    display: inline-block;
    line-height: 25px;
    font-size: 14px;
    color: #555;
    border-bottom: none;
  }

  .post-nav-item a:hover {
    color: #222;
    font-weight: bold;
    border-bottom: none;
  }

  .post-nav-item a:active {
    top: 2px;
  }

  .post-nav-item a:before,
  .post-nav-item a:after {
    display: inline-block;
    width: 16px;
    height: 25px;
    vertical-align: top;
    opacity: 0.4;
    background-size: 16px;
  }

  .post-nav-none a:none {
    content: ' ';
    background-size: 8px;
  }

  .post-nav-none a:hover:none {
    opacity: 1;
  }

  .post-nav-prev a:before {
    content: ' ';
    background: url("data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiA/PjxzdmcgaGVpZ2h0PSIxMnB4IiB2ZXJzaW9uPSIxLjEiIHZpZXdCb3g9IjAgMCA5IDEyIiB3aWR0aD0iOXB4IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnNrZXRjaD0iaHR0cDovL3d3dy5ib2hlbWlhbmNvZGluZy5jb20vc2tldGNoL25zIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+PHRpdGxlLz48ZGVzYy8+PGRlZnMvPjxnIGZpbGw9Im5vbmUiIGZpbGwtcnVsZT0iZXZlbm9kZCIgaWQ9IlBhZ2UtMSIgc3Ryb2tlPSJub25lIiBzdHJva2Utd2lkdGg9IjEiPjxnIGZpbGw9IiMwMDAwMDAiIGlkPSJDb3JlIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgtMjE4LjAwMDAwMCwgLTkwLjAwMDAwMCkiPjxnIGlkPSJjaGV2cm9uLWxlZnQiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIxOC41MDAwMDAsIDkwLjAwMDAwMCkiPjxwYXRoIGQ9Ik03LjQsMS40IEw2LDAgTC04Ljg4MTc4NDJlLTE2LDYgTDYsMTIgTDcuNCwxMC42IEwyLjgsNiBMNy40LDEuNCBaIiBpZD0iU2hhcGUiLz48L2c+PC9nPjwvZz48L3N2Zz4=") no-repeat 0 50%;
    background-size: 8px;
  }

  .post-nav-prev a:hover:before {
    opacity: 1;
  }

  .post-nav-next {
    text-align: right;
  }

  .post-nav-next a:after {
    content: ' ';
    background: url("data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiA/PjxzdmcgaGVpZ2h0PSIxMnB4IiB2ZXJzaW9uPSIxLjEiIHZpZXdCb3g9IjAgMCA5IDEyIiB3aWR0aD0iOXB4IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnNrZXRjaD0iaHR0cDovL3d3dy5ib2hlbWlhbmNvZGluZy5jb20vc2tldGNoL25zIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+PHRpdGxlLz48ZGVzYy8+PGRlZnMvPjxnIGZpbGw9Im5vbmUiIGZpbGwtcnVsZT0iZXZlbm9kZCIgaWQ9IlBhZ2UtMSIgc3Ryb2tlPSJub25lIiBzdHJva2Utd2lkdGg9IjEiPjxnIGZpbGw9IiMwMDAwMDAiIGlkPSJDb3JlIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgtMjYwLjAwMDAwMCwgLTkwLjAwMDAwMCkiPjxnIGlkPSJjaGV2cm9uLXJpZ2h0IiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgyNjAuNTAwMDAwLCA5MC4wMDAwMDApIj48cGF0aCBkPSJNMSwwIEwtMC40LDEuNCBMNC4yLDYgTC0wLjQsMTAuNiBMMSwxMiBMNyw2IEwxLDAgWiIgaWQ9IlNoYXBlIi8+PC9nPjwvZz48L2c+PC9zdmc+") no-repeat 100% 50%;
    background-size: 8px;
  }

  .post-nav-next a:hover:after {
    opacity: 1;
  }
</style>



<div class="post-nav">

  
  <div class="post-nav-none post-nav-item">
    <a href=""> </a>
  </div>
  

  
  <div class="post-nav-next post-nav-item">
    
    <a href="/blog/2019/sound/"> librosa处理音频信号</a>
  </div>
  

</div>

</article>
    </div>

    <footer class="site-footer">
  <div class="container">
    <ul class="social">
  <li><a href="https://twitter.com/penghuailiang" target="_blank"><i class="icon icon-twitter"></i></a></li>
  <li><a href="https://www.zhihu.com/people/huailiangpenguin" target="_blank"><i class="icon icon-zhihu"></i></a></li>
  <li><a href="https://www.facebook.com/profile.php?id=100004290725320" target="_blank"><i class="icon icon-facebook"></i></a></li>
  <li><a href="https://weibo.com/6212299692/profile?topnav=1&wvr=6" target="_blank"><i class="icon icon-sina"></i></a></li>
  <li><a href="https://www.linkedin.com/in/penghuailiang/" target="_blank"><i class="icon icon-linkedin"></i></a></li>
  <li><a href="https://github.com/huailiang" target="_blank"><i class="icon icon-github"></i></a></li>
</ul>
    <p class="txt-medium-gray">
      <small>&copy;2019 All rights reserved. </small>
    </p>
  </div>
</footer>
    <a href="https://github.com/huailiang" target="_blank" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#337ab7; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <script src="//code.jquery.com/jquery-1.11.3.min.js"></script>
    <script>
      $(document).ready(function () {
        $('.sliding-panel-button,.sliding-panel-fade-screen,.sliding-panel-close').on('click touchstart', function (e) {
          $('.sliding-panel-content,.sliding-panel-fade-screen').toggleClass('is-visible');
          e.preventDefault();
        });
      });
    </script>
  </main>
</body>

</html>